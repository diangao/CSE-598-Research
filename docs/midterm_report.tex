\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin=1in]{geometry} 
\usepackage{setspace} 
\usepackage{titlesec}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{hyperref}


\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}


\setstretch{1.15}


\setlength{\parskip}{0.5em}


\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}
\titlespacing*{\section}{0pt}{1.5em}{1em}

\titleformat{\subsection}
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{1.25em}{0.75em}

\title{\Large\textbf{Midterm Report}}
\author{Anish Chandra, Diyan Gao, Linglong Meng}
\date{March 2025}

\begin{document}

\maketitle

\section{Introduction}

Our research investigates the emergent behaviors of large language model (LLM) agents as they learn to strategically utilize external memory systems through explicitly defined function calls. This represents a significant evolution from our initial proposal, which focused primarily on comparative analysis of pre-defined memory architectures. Instead, we have pivoted toward examining how agents autonomously develop memory utilization strategies when given access to multiple memory systems simultaneously.

\subsection{Evolution from Proposal to Current Approach}

While our proposal focused on comparing different memory architectures through controlled experiments with fixed memory retrieval patterns, our current work explores a fundamentally different question: How do LLM agents develop agency in memory management? Initial explorations with $\tau$-bench revealed that the pre-determined memory access patterns constrained our ability to observe emergent behaviors. This led us to reconceptualize our approach, shifting from researcher-determined memory access to agent-directed memory interaction.

This paradigm shift required us to develop a novel experimental framework centered on fine-tuning LLM agents with function-calling capabilities. Rather than embedding agents within fixed memory architectures, we now equip them with explicit memory management functions, allowing them to develop increasingly sophisticated memory utilization strategies through experience. This approach enables us to trace the emergence of memory-aware metacognition in increasingly complex problem-solving scenarios.

The reconceptualized experimental design positions us to address more ambitious research questions about how artificial agents develop and refine cognitive strategies when equipped with externalized memory systems. By observing how agents navigate the trade-offs between different memory systems across varying task complexities, we gain insight into the fundamental relationship between memory architecture and problem-solving capability in artificial intelligence systems.

\subsection{Memory Systems Design}

Our current implementation examines two distinct memory systems, each representing fundamentally different approaches to knowledge organization and retrieval. In our experimental design, we conduct separate trials where the agent is constrained to use only one memory system at a time, allowing us to isolate and analyze the specific impact of each memory architecture on agent performance.

The discrete memory space implements a graph-based representation where game states are encoded as nodes and possible transitions as edges. This architectural choice creates an explicit spatial representation of the problem space, allowing for precise path-based retrieval and deterministic traversal of state transitions. The implementation leverages graph database principles for efficient state tracking and relationship modeling, enabling the agent to construct explicit models of action consequences.

In contrast, the continuous memory space operates through a vector-based representation where experiences are encoded as dense embeddings within a high-dimensional semantic space. This approach facilitates approximate matching and similarity-based retrieval, allowing the agent to identify relevant experiences based on structural or semantic proximity rather than exact matching. This memory system excels at identifying broad patterns and generalizing across similar but non-identical situations.

The agent interacts with these memory systems through specific function calls: discrete memory storage and retrieval in one experimental condition, and continuous memory storage and retrieval in another condition. By constraining the agent to a single memory type per experimental condition, we can directly observe how each memory architecture influences the agent's learning trajectory and strategy development across increasing levels of task complexity.

\subsection{Experimental Framework}

Our experimental framework centers on a progressively challenging series of Tic-Tac-Toe games, where board dimensions increase incrementally from the standard 3×3 configuration to substantially more complex 60×60 boards. This progression creates a controlled complexity gradient that allows us to observe how different memory architectures perform as computational and cognitive demands increase. For each board size, we conduct separate experimental trials with agents constrained to use either the discrete (graph-based) or continuous (vector-based) memory system, creating a comparative analysis across the complexity spectrum.

In each trial, the agent consistently plays against a randomly-moving opponent, creating a stable baseline for measuring performance improvements attributed solely to the memory architecture rather than opponent modeling. This controlled opponent strategy ensures that performance differences can be directly attributed to the memory system's influence on learning and decision-making.

A critical innovation in our experimental methodology is the implementation of comprehensive memory snapshots. After each memory operation, we capture the complete state of the memory system, creating a high-resolution timeline of memory evolution throughout the learning process. These snapshots allow us to trace the agent's developing understanding of the problem space and identify critical learning moments where significant strategic insights emerge. Complementing these snapshots, we maintain detailed logs of function call patterns, recording not only when memory systems are accessed but also the context and apparent purpose of each interaction.

Performance metrics focus on both immediate and cumulative outcomes. We track per-game win rates to measure immediate performance, while cumulative win rates across the complexity gradient reveal broader learning trajectories. By comparing these metrics between discrete and continuous memory conditions, we can identify the relative strengths and limitations of each memory architecture at different complexity levels.

\subsection{Research Questions}

This experimental framework positions us to address several fundamental questions about memory utilization in artificial intelligence systems:

How do different memory architectures affect an agent's learning and performance as task complexity increases? By comparing the performance trajectories of agents using discrete versus continuous memory systems across increasing board sizes, we can identify the relative strengths and limitations of each architecture at different complexity levels. Initial observations suggest that discrete memory systems may provide advantages in simpler problem spaces, while continuous systems might offer benefits as complexity grows.

What patterns emerge in memory storage and retrieval operations across different game phases when the agent is restricted to a specific memory type? We hypothesize that agents will develop memory utilization strategies optimized for their assigned memory architecture, with potentially distinct approaches for opening phases, midgame scenarios, and endgame positions. The transition points between these phases may reveal important insights about how different memory architectures shape strategic thinking.

How does memory architecture influence an agent's ability to learn from experience over time? By analyzing win rate trajectories for each memory condition, we can determine how different memory architectures affect the rate and extent of learning. This analysis may reveal critical thresholds where certain memory architectures provide decisive advantages or limitations.

Can we identify characteristic patterns of memory utilization through snapshot analysis? By examining memory snapshots before and after significant performance improvements, we may be able to identify specific knowledge structures that emerge within each memory architecture and enable higher-level strategy formation. These patterns could provide insights into how different memory systems organize and leverage experiential knowledge.

\section{Methods}

Our initial research direction focused on comparing different external memory architectures for LLM-based agents. This section outlines the methodology we developed and implemented in our codebase, as well as our planned pivot to a new research direction.

\subsection{Original Approach: Memory Architecture Comparison}

Our implemented framework extends the $\tau$-bench ChatReActAgent with pluggable memory components. We successfully built a system with three distinct memory architectures. The GraphMemory module, utilizing NetworkX, represents game states as nodes and actions as edges in a directed graph. This implementation creates a structural representation of the game space, allowing agents to traverse paths of previously seen state-action pairs. Retrieval is based on state similarity (Jaccard similarity of tokenized board states) and returns the most relevant past experiences. The VectorMemory module encodes game states as numerical vectors, embedding the 3×3 Tic-Tac-Toe board into a 9-dimensional vector space where each dimension represents a board position (1 for X, -1 for O, 0 for empty). Retrieval uses cosine similarity to find the most similar past states. Finally, the SemanticMemory approach leverages natural language representations, using sentence transformers to encode game states and strategies as embeddings within a semantic space, allowing retrieval based on conceptual similarity rather than exact state matching.

Each memory architecture was integrated into the ReAct reasoning framework through a MemoryAgent class that augments the standard system prompt with retrieved experiences. The memory-enhanced prompt includes relevant past game states, actions taken in those states, similarity scores for context, and guidance to adapt past experiences to the current situation. This approach allows agents to leverage historical information while maintaining the flexibility to respond to novel situations.

Our experimental framework was implemented to systematically evaluate these architectures in a controlled Tic-Tac-Toe environment. The implementation includes a custom tictactoe\_discrete environment in the $\tau$-bench framework, specialized memory agents (GraphMemoryAgent, VectorMemoryAgent, SemanticMemoryAgent), a comprehensive experiment runner, and detailed performance tracking for win rates and memory statistics. This infrastructure enables rigorous comparison of memory architectures under identical experimental conditions.

Initial validation tests confirmed that each memory architecture functions correctly within our experimental setup and can successfully store and retrieve game states. We observed that different memory architectures led to distinct patterns of state representation and retrieval, suggesting potential differences in strategic reasoning. These early observations provided the empirical foundation for our subsequent research direction.

\subsection{Pivot to Function-Calling for Memory Management}

Based on our preliminary work and evolving research interests, we are now pivoting to a more ambitious research direction. Instead of comparing pre-defined memory architectures, we aim to investigate how LLM agents develop agency in memory management when equipped with function-calling capabilities. Our new approach will fine-tune LLM agents for effective function calling to memory systems, provide agents with discrete (graph-based) and continuous (vector-based) memory functions, study how agents learn to utilize these memory functions across increasing task complexity, and analyze emergent patterns in memory utilization strategies. This shift reflects our recognition that understanding how agents autonomously develop memory utilization strategies may yield more profound insights than comparative analysis of researcher-defined memory systems.

The revised experimental design will use progressively larger Tic-Tac-Toe boards (from 3×3 to 60×60) to create a complexity gradient. For each board size, we will run separate trials where the agent is constrained to use either discrete or continuous memory functions exclusively, allowing for comparative analysis of memory architecture effectiveness across the complexity spectrum. This approach enables us to observe how different memory architectures perform under varying levels of computational and cognitive demand, potentially revealing complementary strengths and context-dependent advantages.

This pivot represents a shift from comparing fixed memory architectures to understanding how agents develop memory utilization strategies when given the agency to manage their own memory operations. While we have completed the groundwork for this new direction, the implementation of the function-calling interface and the scaled complexity experiments remain in progress. The foundational work on memory architectures provides essential technical infrastructure for this new research direction.

\section{Current Progress and Next Steps}

\subsection{Completed Work}

We have successfully implemented and validated three distinct memory architectures (graph-based, vector-based, and semantic), establishing a comprehensive foundation for our research. The memory-augmented agent framework we developed extends the $\tau$-bench environment with sophisticated memory capabilities, enabling controlled experimentation in strategic reasoning tasks. Our custom Tic-Tac-Toe environment serves as an ideal testbed for memory evaluation, providing a well-understood problem space with clear success criteria. Additionally, we have implemented comprehensive data collection mechanisms that capture detailed memory performance metrics, including retrieval times, storage patterns, and win rates.

Our codebase includes robust implementations of base memory classes with clearly defined interfaces for storage and retrieval operations. These interfaces establish a consistent interaction pattern for all memory types, ensuring fair comparison across architectures. The memory-augmented agent classes we developed integrate seamlessly with the ReAct reasoning framework, allowing memory contents to influence decision-making while maintaining the core reasoning process. The experimental runners we created enable systematic evaluation through controlled parameterization, supporting reproducible experimentation and detailed result analysis.

\subsection{Current Limitations}

Our initial approach, while technically sound, revealed several limitations that motivated our pivot to a new research direction. The fixed memory retrieval pattern we initially implemented constrains the agent's ability to develop novel memory strategies, limiting our observation of emergent behaviors. This predetermined approach to memory access restricts the agent's agency and potentially masks more sophisticated memory utilization patterns that might develop under less constrained conditions. Additionally, the standard 3×3 Tic-Tac-Toe environment, while providing a clear and controlled testbed, may be too simple to fully demonstrate the benefits of different memory architectures. The limited state space and strategic depth may not sufficiently challenge memory systems to reveal their distinctive strengths and limitations. Furthermore, our pre-defined memory architectures, while theoretically grounded, restrict agent autonomy in memory management, potentially overlooking more effective hybrid approaches that an agent might develop if given greater flexibility in memory utilization.

\subsection{Next Steps}

For our new research direction, our immediate next steps involve implementing a sophisticated function-calling interface for memory operations. This interface will allow agents to explicitly invoke memory storage and retrieval functions, creating a transparent mechanism for studying memory utilization patterns. We will develop scalable Tic-Tac-Toe environments with incrementally increasing board sizes, creating a complexity gradient that systematically challenges memory systems under progressively more demanding conditions. Alongside these technical developments, we will create comprehensive snapshot mechanisms to capture memory system states throughout the learning process, enabling high-resolution analysis of memory evolution. Finally, we will design nuanced metrics to evaluate memory utilization patterns and strategy development, focusing on both quantitative performance indicators and qualitative assessments of strategic sophistication.

We anticipate that this new direction will yield deeper insights into how artificial agents develop and refine memory-based cognitive strategies in progressive learning scenarios. By studying memory utilization across a complexity gradient, we hope to identify critical thresholds where different memory architectures provide distinct advantages, potentially informing the design of more adaptive and contextually appropriate memory systems for artificial intelligence.

\section{Conclusion}

This midterm report documents our research journey from comparing fixed memory architectures to investigating agent-directed memory utilization through function calling. Our initial implementation of three distinct memory systems (graph-based, vector-based, and semantic) integrated with the $\tau$-bench framework has provided us with valuable insights and a solid technical foundation for our pivot. The development of these systems required addressing fundamental questions about knowledge representation, similarity metrics, and memory-reasoning integration, yielding technical solutions that will continue to inform our research regardless of the specific experimental paradigm.

Our completed work has demonstrated the feasibility of memory-augmented agents within the context of Tic-Tac-Toe gameplay. Each memory architecture has shown unique characteristics in terms of state representation, retrieval patterns, and integration with the ReAct reasoning framework. Graph-based memory excels at capturing explicit strategic relationships, vector-based memory effectively identifies structural similarities across states, and semantic memory reveals conceptual parallels that might escape more rigid representational schemes. These observations have informed our decision to shift toward studying how agents develop agency in memory management, suggesting that different memory systems might offer complementary advantages in different contexts.

The pivot to function-calling for memory management represents a more ambitious and potentially more insightful research direction. By studying how agents learn to strategically utilize different memory systems across a complexity gradient, we aim to contribute to the broader understanding of memory's role in artificial intelligence reasoning. This approach moves beyond comparative analysis to examine how intelligent systems develop metacognitive strategies for memory utilization, potentially revealing principles that generalize beyond our specific experimental context. While we have yet to implement this new approach fully, the groundwork laid in our initial implementation provides a strong foundation for investigating these more sophisticated questions.

Moving forward, we will focus on developing the function-calling interface and scaled complexity experiments. This work will require addressing both technical challenges in implementation and methodological questions in experimental design and analysis. We anticipate that this work will yield valuable insights into how memory architecture shapes strategic reasoning in artificial intelligence systems, with potential implications for the design of more sophisticated cognitive architectures for LLM-based agents. By increasing our understanding of how artificial systems manage and leverage memory, we hope to contribute to the development of more capable, efficient, and adaptable artificial intelligence.

\end{document}
